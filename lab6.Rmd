---
title: "Lab6"
author: "Javier Patron"
date: "`r Sys.Date()`"
output: html_document
---


## Case Study Eel Species Distribution Modeling

This week's lab follows a modeling project described by Elith et al. (2008) (Supplementary Reading)

```{r}
library(tidyverse)
library(tidymodels)
library(janitor)
library(caret)
library(vip)
library(xgboost)

```


## Data
Grab the model training data set from the class Git:
data/eel.model.data.csv

```{r}
eel_data <- read_csv(here::here("eel.model.data.csv")) |> 
  clean_names() |> 
  mutate(angaus = as.factor(angaus))

```


### Split and Resample
Split the joined data from above into a training and test set, stratified by outcome score. Use 10-fold CV to resample the training set, stratified by Angaus

```{r}
#Split the data
eel_split <- initial_split(eel_data, strata = "angaus")

# Crate the testing and testing data
eel_train <- training(eel_split)
eel_test <- testing(eel_split)


# Create the10 fold CV
eel_cv = eel_train |> vfold_cv(v = 10)

```


### Preprocess

Create a recipe to prepare your data for the XGBoost model.  We are interested in predicting the binary outcome variable Angaus which indicates presence or absence of the eel species Anguilla australis

```{r}
eel_recipe <- recipe(angaus ~ .,
                     data = eel_train) |> 
  step_integer(all_predictors(), zero_based = TRUE) |> 
  prep() |> 
  bake(new_data = eel_train)

```

## Tuning XGBoost

```{r}
xgmodel <-parsnip::boost_tree(
  mode = "classification",
  trees = 1000, #nrounds
  learn_rate = tune(), #eta
  sample_size = tune(), #subsample
  mtry = tune(), #colsample_bytree
  min_n = tune(), #min_child_weight
  tree_depth = tune() #max_depth
) %>%
  set_engine("xgboost", 
             objective = "multi:softprob",
             lambda=0, 
             alpha=1, 
             num_class=3,
             verbose=1)

```

Set up the parameters
```{r}
xgboostParams <- dials::parameters(
  min_n(),
  tree_depth(),
  learn_rate(),
  finalize(mtry(),select(eel_recipe,- angaus)), #mtry() is the number of variables used in the making of each tree we need to bound it by the number of variables available.
  sample_size = sample_prop(c(0.4, 0.9))
)
```

Create a workflow 
```{r}
xgWorkflow <- 
  workflows::workflow() %>%
  add_model(xgmodel) %>% 
  add_formula(angaus ~ .)
```

XGBoost we will tune 3 times. We are creating this tine in three different phases
1) Just a tune for the learning rate

2) Tune each one of the tree parameters


3) Tune with the stochastic sampling (for the rows)


### Tune Learning Rate

Following the XGBoost tuning strategy outlined on Monday, first we conduct tuning on just the learn_rate parameter:

1.  Create a model specification using {xgboost} for the estimation

```{r}
# Define the parameter grid
param_grid <- list(
  booster = "gbtree",
  eta = c(0.01, 0.1, 0.5),
  max_depth = c(3, 6, 9),
  subsample = c(0.5, 0.8, 1),
  lambda = c(0, 1, 10),
  alpha = c(0, 1, 10)
)

# Train and cross-validate the model
xgb_cv <- xgb.cv(
  data = X,
  label = Y,
  nrounds = 1000,
  nfold = 10,
  params = param_grid,
  early_stopping_rounds = 10,
  metrics = "error",
  seed = 123
)

# Select the best hyperparameters
best_params <- xgb_cv$best_param

```


-   Only specify one parameter to tune()



2.  Set up a grid to tune your model by using a range of learning rate parameter values: expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))

Create the grid_max_entropy with the parameters just created
```{r}
set.seed(123)
xgGrid <- dials::grid_max_entropy(xgboostParams, size = 100)

expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))

```


-   Use appropriate metrics argument(s) - Computational efficiency becomes a factor as models get more complex and data get larger. Record the time it takes to run. Do this for each tuning phase you run.You could use {tictoc} or Sys.time().

```{r}
xgTuned <- tune_grid(
  object = xgWorkflow,
  resamples = eel_cv,
  grid      = xgGrid,
  metrics   = metric_set(mn_log_loss),
  control   = control_grid(verbose = TRUE))

```

3.  Show the performance of the best models and the estimates for the learning rate parameter values associated with each.


```{r}
xgTuned %>% tune::show_best(metric = "mn_log_loss") %>% kableExtra::kable()
```




### Tune Tree Parameters

1.  Create a new specification where you set the learning rate (which you already optimized) and tune the tree parameters.

2.  Set up a tuning grid. This time use grid_max_entropy() to get a representative sampling of the parameter space

3.  Show the performance of the best models and the estimates for the tree parameter values associated with each.

### Tune Stochastic Parameters

1.  Create a new specification where you set the learning rate and tree parameters (which you already optimized) and tune the stochastic parameters.

2.  Set up a tuning grid. Use grid_max_entropy() again.

3.  Show the performance of the best models and the estimates for the tree parameter values associated with each.

## Finalize workflow and make final prediction

1.  Assemble your final workflow will all of your optimized parameters and do a final fit.

2. How well did your model perform? What types of errors did it make?

## Fit your model the evaluation data and compare performance

1.  Now fit your final model to the big dataset: data/eval.data.csv

2.  How does your model perform on this data?

3.  How do your results compare to those of Elith et al.?

-   Use {vip} to compare variable importance
-   What do your variable importance results tell you about the distribution of this eel species?