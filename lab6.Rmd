---
title: "Lab6"
author: "Javier Patron"
date: "`r Sys.Date()`"
output: html_document
---


## Case Study Eel Species Distribution Modeling
This week's lab follows a modeling project described by Elith et al. (2008) (Supplementary Reading)

```{r}
library(tidyverse)
library(tidymodels)
library(janitor)
library(caret)
library(vip)
library(xgboost)

```


## Data
Grab the model training data set from the class Git:
data/eel.model.data.csv

```{r}
eel_data <- read_csv(here::here("eel.model.data.csv")) |> 
  clean_names() |> 
  mutate(angaus = as.factor(angaus))

```


### Split and Resample
Split the joined data from above into a training and test set, stratified by outcome score. Use 10-fold CV to resample the training set, stratified by Angaus

```{r}
#Split the data
eel_split <- initial_split(eel_data, strata = "angaus")

# Crate the testing and testing data
eel_train <- training(eel_split)
eel_test <- testing(eel_split)


# Create the10 fold CV
eel_cv = eel_train |> vfold_cv(v = 10)

```

### Preprocess

Create a recipe to prepare your data for the XGBoost model.  We are interested in predicting the binary outcome variable Angaus which indicates presence or absence of the eel species Anguilla australis

```{r}
eel_recipe <- recipe(angaus ~ .,
                     data = eel_train) |> 
  step_integer(all_predictors(), zero_based = TRUE) |> 
  prep() |> 
  bake(new_data = eel_train)

```


### Tune Learning Rate

Following the XGBoost tuning strategy outlined on Monday, first we conduct tuning on just the `learn_rate` parameter:

1.  Create a model specification using {xgboost} for the estimation

-   Only specify one parameter to tune()
```{r}
xg_model_learn <-parsnip::boost_tree(
  mode = "classification",
  trees = 20, # Recommended 3,000
  learn_rate = tune(), #eta
) 
  # set_engine("xgboost", 
  #            objective = "multi:softprob",
  #            lambda=0, 
  #            alpha=1, 
  #            num_class=3,
  #            verbose=1)

```

Set up the parameters
```{r}
xgboostParams_learn <- dials::parameters(
  learn_rate(),
  finalize(mtry(),select(eel_recipe,- angaus)), #mtry() is the number of variables used in the making of each tree we need to bound it by the number of variables available.
  sample_size = sample_prop(c(0.4, 0.9))
)
```


2.  Set up a grid to tune your model by using a range of learning rate parameter values: expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))
```{r}
set.seed(123)
xg_grid_learn <- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))

```


-   Use appropriate metrics argument(s) - Computational efficiency becomes a factor as models get more complex and data get larger. Record the time it takes to run. Do this for each tuning phase you run.You could use {tictoc} or Sys.time().

Create a workflow 
```{r}
xgWorkflow_learn <- 
  workflows::workflow() %>%
  add_model(xg_model_learn) %>% 
  add_formula(angaus ~ .)

```

Tune your grid with tune_grid. (tune_grid() runs a set of performance metrics (e.g. accuracy or RMSE) for a pre-defined set of tuning parameters that correspond to a model or recipe across one or more resamples of the data.

```{r}
xg_learn_tuned <- tune_grid(
  object = xgWorkflow_learn,
  resamples = eel_cv,
  grid      = xg_grid_learn,
  metrics   = metric_set(mn_log_loss),
  control   = control_grid(verbose = TRUE))

```

3.  Show the performance of the best models and the estimates for the learning rate parameter values associated with each.

```{r}
best_learn <- xg_learn_tuned %>% tune::show_best(metric = "mn_log_loss")

best_learn

```


### Tune Tree Parameters

1.  Create a new specification where you set the learning rate (which you already optimized) and tune the tree parameters.

```{r}
xgmodel_three <-parsnip::boost_tree(
  mode = "classification",
  trees = 30, # Recommended 3,000
  learn_rate = xg_learn_tuned, #eta
  mtry = tune(), #colsample_bytree
  min_n = tune(), #min_child_weight
  tree_depth = tune() #max_depth
) 
  # set_engine("xgboost", 
  #            objective = "multi:softprob",
  #            lambda=0, 
  #            alpha=1, 
  #            num_class=3,
  #            verbose=1)
```

Set up the parameters
```{r}
xgboostParams <- dials::parameters(
  min_n(),
  tree_depth(),
  learn_rate(),
  finalize(mtry(),select(eel_recipe,- angaus)), #mtry() is the number of variables used in the making of each tree we need to bound it by the number of variables available.
  sample_size = sample_prop(c(0.4, 0.9))
)
```


Create a workflow 
```{r}
xg_workflow_three <- 
  workflows::workflow() %>%
  add_model(xgmodel_three) %>% 
  add_formula(angaus ~ .)

```


2.  Set up a tuning grid. This time use grid_max_entropy() to get a representative sampling of the parameter space

```{r}

xg_grid_maxent <- dials::grid_max_entropy(xgboostParams, size = 100) #GRID specs from the book

```


```{r}

xg_three_tuned <- tune_grid(
  object = xg_workflow_three,
  resamples = eel_cv,
  grid      = xg_grid_maxent ,
  metrics   = metric_set(mn_log_loss),
  control   = control_grid(verbose = TRUE))

```

3.  Show the performance of the best models and the estimates for the tree parameter values associated with each.

```{r}
xgTuned %>% tune::show_best(metric = "mn_log_loss")
```



### Tune Stochastic Parameters

1.  Create a new specification where you set the learning rate and tree parameters (which you already optimized) and tune the stochastic parameters.


```{r}
xgmodel_stochastic <-parsnip::boost_tree(
  mode = "classification",
  trees = 100, # Recommended 3,000
  learn_rate = xg_learn_tuned, #eta
  sample_size = tune(), #stochatic
  mtry = txg_three_tuned, #colsample_bytree
  min_n = xg_three_tuned, #min_child_weight
  tree_depth = xg_three_tuned #max_depth
) 
  # set_engine("xgboost", 
  #            objective = "multi:softprob",
  #            lambda=0, 
  #            alpha=1, 
  #            num_class=3,
  #            verbose=1)
```



2.  Set up a tuning grid. Use grid_max_entropy() again.

3.  Show the performance of the best models and the estimates for the tree parameter values associated with each.





## Finalize workflow and make final prediction

1.  Assemble your final workflow will all of your optimized parameters and do a final fit.

```{r}
xgmodel_stochastic %>% collect_metrics() %>% 
  select(mean, mtry:sample_size) %>% 
  data.table %>% 
  melt(id="mean") %>% 
  ggplot(aes(y=mean,x=value,colour=variable)) + 
  geom_point(show.legend = FALSE) + 
  facet_wrap(variable~. , scales="free") + theme_bw() +
  labs(y="Mean log-loss", x = "Parameter")
```




2. How well did your model perform? What types of errors did it make?

## Fit your model the evaluation data and compare performance

1.  Now fit your final model to the big dataset: data/eval.data.csv

2.  How does your model perform on this data?

3.  How do your results compare to those of Elith et al.?

-   Use {vip} to compare variable importance
-   What do your variable importance results tell you about the distribution of this eel species?